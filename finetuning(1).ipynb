{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "44a4627c-838c-4c27-9269-123498dfa4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import datasets \n",
    "import transformers \n",
    "import peft\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c5ac5503-5b80-4874-a753-5e31a746bb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a709bb0-4e38-448f-8a9b-5b1dc6c3d6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.load_dataset('imdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "557c2b3c-7434-48ae-853c-f364563ec548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    unsupervised: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "51f2eaae-3e9a-4d4b-88b0-c6fc1ad946b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f27c9a02-4d6b-4d9a-b4b9-523da02e4cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "# Number of classes in your classification task (e.g., 2 for binary sentiment)\n",
    "NUM_LABELS = 2\n",
    "\n",
    "# You may also want to map the class IDs to human-readable names\n",
    "id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
    "label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}\n",
    "\n",
    "# Set the device to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fa9a11f-e682-41c0-98d9-8d4e6a7f6547",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    # 'text' is the column name containing the input sentence\n",
    "    return tokenizer(\n",
    "        examples[\"text\"],\n",
    "        truncation=True, # Truncate long sequences\n",
    "        padding=\"max_length\" # Pad all sequences to max length\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "231e3c34-5c59-4dcd-b766-cd47fec9e5db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 25000/25000 [00:09<00:00, 2536.41 examples/s]\n",
      "Map: 100%|██████████| 25000/25000 [00:09<00:00, 2545.51 examples/s]\n",
      "Map: 100%|██████████| 50000/50000 [00:20<00:00, 2444.10 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True # Process multiple examples at once for speed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54274b03-0354-4df6-a394-cefc5e325768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "795c40e0-4dd7-41aa-9b05-bfa1345d04a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the original text column and any other unnecessary columns\n",
    "tokenized_datasets = tokenized_datasets.remove_columns([\"text\"])\n",
    "\n",
    "# If the label column isn't named 'labels' already, rename it:\n",
    "if 'label' in tokenized_datasets['train'].column_names:\n",
    "    tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
    "\n",
    "# Set the format to PyTorch tensors for training\n",
    "tokenized_datasets.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b47c12cd-db9a-4ca1-9440-a3fb1dba8bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "835fc01c-bcda-443b-a6d9-e9c007bc0702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 90/10 train/validation split from the original 'train' set\n",
    "train_val_split = tokenized_datasets[\"train\"].train_test_split(test_size=0.1, seed=42)\n",
    "\n",
    "# Reassign the splits in the DatasetDict\n",
    "tokenized_datasets[\"train\"] = train_val_split[\"train\"]\n",
    "tokenized_datasets[\"validation\"] = train_val_split[\"test\"]\n",
    "# The original 'test' split remains the final test set\n",
    "# tokenized_datasets[\"test\"] is already available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5b72b3c-d18b-4029-9b75-890ada567b1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 22500\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    unsupervised: Dataset({\n",
       "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 2500\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d92a09e-4f10-4842-aee3-ec8b8f271cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base Model Selection and Configuration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77ca22c2-9b96-40b0-a3a1-54a65c8a83fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded and moved to cuda.\n",
      "Model Classification Head Output Features (num_labels): 2\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "# Load the model with the sequence classification head\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    num_labels=NUM_LABELS,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n",
    "\n",
    "# Move the model to the appropriate device\n",
    "model.to(device)\n",
    "\n",
    "print(f\"Model loaded and moved to {device}.\")\n",
    "print(f\"Model Classification Head Output Features (num_labels): {model.config.num_labels}\")\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5663739f-f92e-4f20-b82f-3c83f19b5471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PEFT Implementation (LoRA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b00e992-1a95-4f29-a98e-c9d7c1693fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 296,450 || all params: 109,780,228 || trainable%: 0.2700\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "# Define the LoRA configuration\n",
    "# We target the query (q) and value (v) matrices in the attention blocks.\n",
    "# This is the most common and effective practice for LoRA.\n",
    "config = LoraConfig(\n",
    "    r=8,  # The LoRA rank. A lower rank means fewer parameters. Common values are 8, 16, 32.\n",
    "    lora_alpha=16, # Scaling factor for the LoRA weights. Should be >= r.\n",
    "    target_modules=[\"query\", \"value\"], # The modules to apply LoRA to.\n",
    "    lora_dropout=0.1, # Dropout applied to the LoRA weights.\n",
    "    bias=\"none\", # We usually don't fine-tune the bias terms.\n",
    "    task_type=TaskType.SEQ_CLS # Specify the task type for correct handling of the model head.\n",
    ")\n",
    "\n",
    "# Apply the LoRA configuration to the base model\n",
    "lora_model = get_peft_model(model, config)\n",
    "\n",
    "# Print the number of trainable parameters for comparison\n",
    "lora_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02bac039-9eae-4621-ace1-dbd0349c68a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "644d5c00-3a8f-4480-8535-f1d71c24f411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): BertForSequenceClassification(\n",
       "      (bert): BertModel(\n",
       "        (embeddings): BertEmbeddings(\n",
       "          (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "          (position_embeddings): Embedding(512, 768)\n",
       "          (token_type_embeddings): Embedding(2, 768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder): BertEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-11): 12 x BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSdpaSelfAttention(\n",
       "                  (query): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (pooler): BertPooler(\n",
       "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (activation): Tanh()\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (classifier): ModulesToSaveWrapper(\n",
       "        (original_module): Linear(in_features=768, out_features=2, bias=True)\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): Linear(in_features=768, out_features=2, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "# Define the directory where model checkpoints and logs will be saved\n",
    "output_dir = \"lora_finetuned_model_output\"\n",
    "\n",
    "# Define the training hyper-parameters\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    num_train_epochs=3, # Run for a small number of epochs, typical for fine-tuning\n",
    "    per_device_train_batch_size=16, # Adjust based on your GPU memory\n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_steps=500, # Number of steps for learning rate warmup\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=100,\n",
    "    # Setting evaluation and save strategies to 'epoch'\n",
    "    eval_strategy=\"epoch\", \n",
    "    save_strategy=\"epoch\", \n",
    "    load_best_model_at_end=True, # Will save and load the best checkpoint\n",
    "    fp16=torch.cuda.is_available(), # Enable mixed precision for faster training if GPU is available\n",
    ")\n",
    "\n",
    "# Set the device (redundant if using Trainer, but good for completeness)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "lora_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "48683774-e0f9-43e9-8944-d3cf45cc140e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\awubs\\AppData\\Local\\Temp\\ipykernel_24036\\3299602666.py:2: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Fine-Tuning ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4221' max='4221' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4221/4221 1:40:14, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.265200</td>\n",
       "      <td>0.292220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.246600</td>\n",
       "      <td>0.244614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.260800</td>\n",
       "      <td>0.225686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fine-Tuning Complete ---\n"
     ]
    }
   ],
   "source": [
    "# The trainer brings together the model, data, and arguments\n",
    "trainer = Trainer(\n",
    "    model=lora_model, # The LoRA-enabled PEFT model from Step 6\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    # We are intentionally skipping the compute_metrics argument for now as requested.\n",
    ")\n",
    "\n",
    "# Start the fine-tuning process\n",
    "print(\"--- Starting Fine-Tuning ---\")\n",
    "trainer.train()\n",
    "print(\"--- Fine-Tuning Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82308159-ef8f-4ce7-ba43-109ba259ffaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b90d125-b05b-4e68-a851-67f5bbba8797",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "# Load the desired evaluation metrics\n",
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "f1_metric = evaluate.load(\"f1\")\n",
    "precision_metric = evaluate.load(\"precision\")\n",
    "recall_metric = evaluate.load(\"recall\")\n",
    "\n",
    "def compute_metrics_full(eval_pred):\n",
    "    # eval_pred is a named tuple with (predictions, label_ids)\n",
    "    logits, labels = eval_pred\n",
    "    \n",
    "    # Get the predicted class IDs\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    \n",
    "    # Calculate all metrics\n",
    "    accuracy = accuracy_metric.compute(predictions=predictions, references=labels)\n",
    "    # Note: For binary classification (like IMDb), we use average='binary' for F1, \n",
    "    # precision, and recall on the positive class (label 1).\n",
    "    f1 = f1_metric.compute(predictions=predictions, references=labels, average='binary')\n",
    "    precision = precision_metric.compute(predictions=predictions, references=labels, average='binary')\n",
    "    recall = recall_metric.compute(predictions=predictions, references=labels, average='binary')\n",
    "\n",
    "    # Return a dictionary of all results\n",
    "    return {\n",
    "        \"accuracy\": accuracy[\"accuracy\"],\n",
    "        \"f1\": f1[\"f1\"],\n",
    "        \"precision\": precision[\"precision\"],\n",
    "        \"recall\": recall[\"recall\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ac1740cd-8b9f-4dc7-8792-7c27bbbcbf41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\awubs\\AppData\\Local\\Temp\\ipykernel_24036\\2696321795.py:5: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1563' max='1563' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1563/1563 11:34]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Test Set Evaluation Results ---\n",
      "{'eval_loss': 0.21576179563999176, 'eval_model_preparation_time': 0.0103, 'eval_accuracy': 0.91552, 'eval_f1': 0.9168634860651866, 'eval_precision': 0.902510849349039, 'eval_recall': 0.93168, 'eval_runtime': 696.0286, 'eval_samples_per_second': 35.918, 'eval_steps_per_second': 2.246}\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'lora_model' contains the best weights loaded after training\n",
    "# We can re-use the trainer configuration, but explicitly pass the metric function\n",
    "\n",
    "# Re-initialize the Trainer with the compute_metrics_full function\n",
    "trainer = Trainer(\n",
    "    model=lora_model, # The fine-tuned LoRA-enabled PEFT model\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"], # Still need the eval set, even if only testing\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics_full, # <--- Now including the full metrics\n",
    ")\n",
    "\n",
    "test_results = trainer.evaluate(eval_dataset=tokenized_datasets[\"test\"])\n",
    "\n",
    "print(\"\\n--- Final Test Set Evaluation Results ---\")\n",
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0534ab03-15ef-493b-9fbf-8cf820deed6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Cases: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "501231a4-5730-4d1e-b718-022722e7627e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Case 1 Input\n",
    "raw_text = \"This movie was pretty good! Can't believe I loved it that much!\"\n",
    "\n",
    "# Tokenize the raw text\n",
    "# Ensure truncation and padding match the training setup\n",
    "tokenized_input = tokenizer(\n",
    "    raw_text,\n",
    "    truncation=True,\n",
    "    padding=\"max_length\",\n",
    "    return_tensors=\"pt\"  # Return PyTorch tensors\n",
    ")\n",
    "\n",
    "# Move the input tensors to the same device as the model\n",
    "input_ids = tokenized_input[\"input_ids\"].to(device)\n",
    "attention_mask = tokenized_input[\"attention_mask\"].to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3a871169-45e0-4605-9889-f21292bdbdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model to evaluation mode\n",
    "lora_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Pass input through the model\n",
    "    outputs = lora_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "# The model outputs a dictionary-like object, often with a 'logits' key\n",
    "logits = outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "791679f3-8260-4d0d-a474-ab12e164d576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Test Case 1 Results ---\n",
      "Input Text: 'This movie was pretty good! Can't believe I loved it that much!'\n",
      "Predicted Class ID: 1\n",
      "Final Prediction: **POSITIVE**\n"
     ]
    }
   ],
   "source": [
    "# Get the predicted class index (the index with the highest logit)\n",
    "predicted_class_id = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "# Map the index back to the label (assuming your ID mapping from Step 5a)\n",
    "# id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
    "predicted_label = lora_model.config.id2label[predicted_class_id]\n",
    "\n",
    "# Print the result\n",
    "print(f\"--- Test Case 1 Results ---\")\n",
    "print(f\"Input Text: '{raw_text}'\")\n",
    "print(f\"Predicted Class ID: {predicted_class_id}\")\n",
    "print(f\"Final Prediction: **{predicted_label}**\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d394026a-c372-4f6c-9bd2-df5e729418fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Case 2 Input\n",
    "raw_text= \"Loved the movie. It was the biggest piece of garbage. Ever. Except I loved it.\"\n",
    "\n",
    "# Tokenize the raw text\n",
    "# Ensure truncation and padding match the training setup\n",
    "tokenized_input = tokenizer(\n",
    "    raw_text,\n",
    "    truncation=True,\n",
    "    padding=\"max_length\",\n",
    "    return_tensors=\"pt\"  # Return PyTorch tensors\n",
    ")\n",
    "\n",
    "# Move the input tensors to the same device as the model\n",
    "input_ids = tokenized_input[\"input_ids\"].to(device)\n",
    "attention_mask = tokenized_input[\"attention_mask\"].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e044ee4f-b037-48f2-b088-77741259d7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model to evaluation mode\n",
    "lora_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Pass input through the model\n",
    "    outputs = lora_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "# The model outputs a dictionary-like object, often with a 'logits' key\n",
    "logits = outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a8e4ac2c-6128-435c-b5a4-fdff586c10b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Test Case 2 Results ---\n",
      "Input Text: 'Loved the movie. It was the biggest piece of garbage. Ever. Except I loved it.'\n",
      "Predicted Class ID: 1\n",
      "Final Prediction: **POSITIVE**\n"
     ]
    }
   ],
   "source": [
    "# Get the predicted class index (the index with the highest logit)\n",
    "predicted_class_id = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "# Map the index back to the label (assuming your ID mapping from Step 5a)\n",
    "# id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
    "predicted_label = lora_model.config.id2label[predicted_class_id]\n",
    "\n",
    "# Print the result\n",
    "print(f\"--- Test Case 2 Results ---\")\n",
    "print(f\"Input Text: '{raw_text}'\")\n",
    "print(f\"Predicted Class ID: {predicted_class_id}\")\n",
    "print(f\"Final Prediction: **{predicted_label}**\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307fe881-146e-4660-aca1-eea1092de82c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
